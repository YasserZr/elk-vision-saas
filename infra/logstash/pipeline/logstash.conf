input {
  # TCP input for log forwarding from backend
  tcp {
    port => 5000
    codec => json_lines
    type => "backend"
  }
  
  # UDP input (alternative, faster but less reliable)
  udp {
    port => 5001
    codec => json_lines
    type => "backend_udp"
  }
  
  # Beats input for external log shippers
  beats {
    port => 5044
    type => "beats"
  }
}

filter {
  # Parse timestamp if not already present
  if ![timestamp] {
    date {
      match => ["@timestamp", "ISO8601"]
      target => "@timestamp"
    }
  }
  
  # Extract log level and normalize
  if [level] {
    mutate {
      uppercase => ["level"]
    }
  }
  
  # Add processing metadata
  mutate {
    add_field => {
      "[@metadata][index_prefix]" => "logs"
      "processed_at" => "%{+YYYY-MM-dd'T'HH:mm:ss.SSSZ}"
      "ingestion_pipeline" => "logstash"
    }
  }
  
  # Tenant-based index routing
  if [tenant_id] {
    mutate {
      add_field => {
        "[@metadata][tenant]" => "%{tenant_id}"
      }
    }
  } else {
    mutate {
      add_field => {
        "[@metadata][tenant]" => "default"
      }
      add_field => {
        "tenant_id" => "default"
      }
    }
  }
  
  # Extract service information
  if [service_name] {
    mutate {
      add_tag => ["service:%{service_name}"]
    }
  }
  
  # Environment tagging
  if [environment] {
    mutate {
      add_tag => ["env:%{environment}"]
    }
  }
  
  # Parse JSON message field if it's a string
  if [message] =~ /^\{.*\}$/ {
    json {
      source => "message"
      target => "parsed_message"
      skip_on_invalid_json => true
    }
  }
  
  # GeoIP enrichment if IP field exists
  if [client_ip] or [ip] {
    geoip {
      source => "[client_ip]"
      target => "geoip"
      fallback => "[ip]"
    }
  }
  
  # Drop test/health check messages (optional)
  if [source] == "health_check" {
    drop { }
  }
}

output {
  # Output to Elasticsearch with dynamic index
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    user => "elastic"
    password => "changeme"
    
    # Dynamic index based on tenant and date
    index => "logs-%{[@metadata][tenant]}-%{+YYYY.MM}"
    
    # Performance tuning
    http_compression => true
  }
  
  # Debug output (remove in production)
  stdout {
    codec => rubydebug {
      metadata => true
    }
  }
}
